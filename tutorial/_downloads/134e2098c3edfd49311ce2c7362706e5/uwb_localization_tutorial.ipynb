{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Tutorial for UWB Localization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport torch.nn as nn\nimport os\n\nfrom pysensing.uwb.datasets.get_dataloader import *\nfrom pysensing.uwb.models.get_model import *\nfrom pysensing.uwb.training.localization import *\nfrom pysensing.uwb.inference.predict import *\nfrom pysensing.uwb.inference.embedding import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download Data from Cloud Storage\n\nOpen the following linke in your browser to download Localization datasets:\n\n[Download Pedestrian_Tracking Dataset](https://pysensing.oss-ap-southeast-1.aliyuncs.com/data/uwb/Pedestrian_Tracking.zip) \\\n[...]()\n\n### Unzip the downloaded file and move to your data folder. For HAR, the data folder should look like this:\n|---data \n|------|---localization \n|------|------|---Pedestrian_Tracking \n|------|------|------|---processed_data\n|------|------|------|------|---AnchorPos.mat\n|------|------|------|------|---Bg_CIR_VAR.mat\n|------|------|------|------|---Dyn_CIR_VAR.mat\n|------|------|------|---raw_data\n......\n```\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the data\nHuman action recognition dataset: \n\nHuman Tracking Dataset\n- UWB size : n x 1 x 500 x 2\n\nDataset name choices are:\n- 'pedestrian_tracking_mod1_CIR'\n- 'pedestrian_tracking_mod2_CIR'\n- 'pedestrian_tracking_mod3_CIR'\n- 'pedestrian_tracking_mod1_Var'\n- 'pedestrian_tracking_mod2_Var'\n- 'pedestrian_tracking_mod3_Var'\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "root = './data' \ntrain_loader, val_loader, test_loader = load_localization_dataset(root, 'pedestrian_tracking_mod1_CIR')\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nfor data in train_loader:\n    x, y = data\n    print(x.size())\n    print(y.size())\n    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the model\nModel zoo:\nResNet\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = load_localization_model(dataset_name = 'human_tracking', model_name = 'resnet')\nprint(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model train\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nlocalization_training(\n    root = root,\n    dataset_name='pedestrian_tracking_mod1_CIR',\n    model_name='resnet',\n    num_epochs=1,\n    learning_rate=0.001,\n    save_weights=True,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model inference\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "localization_predictor = predictor(\n    task='localization', \n    dataset_name='human_tracking', \n    model_name='resnet',\n    pt_weights = './human_tracking_weights.pth'\n)\nfor data in test_loader:\n    x, y = data\n    break\noutputs = localization_predictor.predict(x)\nprint(\"output shape:\", outputs.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate embedding\n- noted that the `model_name` variable defined in `load_model` function represents the model structure name, and in `load_pretrain_weights` function represents the model structure and pretrain dataset name.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = load_localization_model(dataset_name = 'human_tracking', model_name = 'resnet')\nmodel = load_pretrain_weights(model, dataset_name = 'human_tracking', model_name = 'CIR_model', device=device)\nuwb_embedding = localization_uwb_embedding(x, model, device)\nprint('uwb_embedding shape: ', uwb_embedding.shape)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}