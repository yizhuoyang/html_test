{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Acoustic Augmentation.Signal_aug Tutorial\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "!pip install pysensing\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this tutorial, we will be implementing a simple acoustic.augmentation.sig_aug\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport torchaudio\nimport matplotlib.pyplot as plt\nfrom pysensing.acoustic.augmentation import signal_aug\nfrom pysensing.acoustic.preprocessing import transform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the audio\nFirst, the example audio is loaded\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define the plot function\ndef plot(audio_data_list, titles,channel_first=True):\n    num_audios = len(audio_data_list)\n    fig, axes = plt.subplots(num_audios, 1, figsize=(12, 8))\n    if num_audios == 1:\n        axes = [axes]\n    for ax, audio_data, title in zip(axes, audio_data_list, titles):\n        if channel_first==False:\n            ax.plot(audio_data.numpy())\n        else:\n            ax.plot(audio_data[0].numpy())\n        ax.set_title(title)\n    fig.tight_layout()\n    plt.show()\n\n# Load the data\n# Load the data\nwaveform, sample_rate = torchaudio.load('example_data/example_audio.wav')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Add Noise\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "noise = torch.randn_like(waveform)\nadd_noise_0 = signal_aug.add_noise(noise,torch.tensor([0]))\nadd_noise_5 = signal_aug.add_noise(noise,torch.tensor([20]))\n\nnoise_data_0 = add_noise_0(waveform)\nnoise_data_5 = add_noise_5(waveform)\n\nplot([waveform,noise_data_5,noise_data_0],['Original','SNR=20','SNR=0'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Add echo\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "waveform, sample_rate = torchaudio.load('example_data/example_audio.wav',channels_first=False)\nadd_echo_tran = signal_aug.add_echo(sample_rate,in_gain=0.6,out_gain=0.3,delays=[1000],decays=[0.5])\necho_data = add_echo_tran(waveform)\n\nplot([waveform,echo_data],['Original','Add_echo'],False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Add atempo\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "add_echo_tran = signal_aug.add_echo(sample_rate,in_gain=0.6,out_gain=0.3,delays=[1000],decays=[0.5])\necho_data = add_echo_tran(waveform)\n\nplot([waveform,echo_data],['Original','Add_echo'],False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Add chorus\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "add_chorus_trans = signal_aug.add_chorus(sample_rate,in_gain=0.6,out_gain=0.3,delays=[1000],decays=[0.5],speeds=[0.25],depths=[2.0])\nchorus_data        = add_chorus_trans(waveform)\nplot([waveform,chorus_data],['Original','Add_chorus'],False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And that's it. We're done with our acoustic augmentation.signal_aug tutorials. Thanks for reading.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}