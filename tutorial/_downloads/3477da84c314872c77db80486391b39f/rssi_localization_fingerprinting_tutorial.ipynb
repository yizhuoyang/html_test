{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# RSSI Localization Fingerprinting Tutorial\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# !pip install pysensing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this tutorial, we will be implementing codes for rssi localization fingerprinting\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport torch\nfrom torch.optim import Adam, SGD\nfrom pysensing.rssi.datasets.ntu_iot_rssi import get_dataloader_ntuiotrssi\nfrom pysensing.rssi.datasets.uji_indoor_loc import get_dataloader_ujiindoorloc\nfrom pysensing.rssi.datasets.download import download_dataset\nfrom pysensing.rssi.inference.embedding import rssi_embedding\nfrom pysensing.rssi.models.localization.load_model import create_model\nfrom pysensing.rssi.models.localization.fingerprinting import MLP, CNN, WKNN, LSTM\nfrom pysensing.rssi.inference.train import train_model\nimport warnings\n\nwarnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download the NTU IoT Lab RSSI Data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "root_data = \"./\"\ndownload_dataset(\"NTUIoTRSSI\", root_data)\ndir_data = os.path.join(root_data, \"NTUIoTRSSI\")\n\npath_train = os.path.join(dir_data, \"data_train.txt\")\nloader_train = get_dataloader_ntuiotrssi(path_train, batch_size=32, is_train=True)\nn_samples_train = len(loader_train.dataset)\npath_test = os.path.join(dir_data, \"data_test.txt\")\nloader_test = get_dataloader_ntuiotrssi(path_test, batch_size=32, is_train=False)\nn_samples_test = len(loader_test.dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Non-Trainable Method: Weighted K-Nearest Neighbors\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset_train = loader_train.dataset\ndataset_train.get_compact()\ndataset_test = loader_test.dataset\nsample_test_rss, sample_test_pos = dataset_test.__getitem__(0)\n\npos_train, rss_train = dataset_train.compact_set[:, :2], dataset_train.compact_set[:, 2:]\nwknn_estimator = WKNN(pos_train, rss_train)\nwknn_est_pos = wknn_estimator(sample_test_rss, K=5)\nprint(\"Ground Truth Position: {}. Estimated Position: {}\".format(sample_test_pos.cpu().numpy(), wknn_est_pos))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Trainable Method: MLP\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mlp_estimator = train_model(model_name=\"MLP\", dataset_name=\"NTUIoTRSSI\", regression=True, optimizer=\"SGD\", epochs=50, batch_size=32, lr=1e-3, dir_save=None)\n\nmlp_estimator = mlp_estimator.cpu()\nmlp_estimator.eval()\nmlp_est_pos = mlp_estimator(sample_test_rss)\nprint(\"Ground Truth Position: {}. Estimated Position: {}\".format(sample_test_pos.cpu().numpy(), mlp_est_pos.cpu().detach().numpy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Trainable Method: CNN (1D)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cnn_estimator = train_model(model_name=\"CNN\", dataset_name=\"NTUIoTRSSI\", regression=True, optimizer=\"SGD\", epochs=50, batch_size=32, lr=1e-3, dir_save=None)\n\ncnn_estimator = cnn_estimator.cpu()\ncnn_estimator.eval()\ncnn_est_pos = cnn_estimator(sample_test_rss.unsqueeze(0))\nprint(\"Ground Truth Position: {}. Estimated Position: {}\".format(sample_test_pos.cpu().numpy(), cnn_est_pos.cpu().detach().numpy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Trainable Method: LSTM\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "lstm_estimator = train_model(model_name=\"LSTM\", dataset_name=\"NTUIoTRSSI\", regression=True, optimizer=\"SGD\", epochs=50, batch_size=32, lr=1e-3, dir_save=None)\n\nlstm_estimator = lstm_estimator.cpu()\nlstm_estimator.eval()\nlstm_est_pos = lstm_estimator(sample_test_rss.unsqueeze(0))\nprint(\"Ground Truth Position: {}. Estimated Position: {}\".format(sample_test_pos.cpu().numpy(), lstm_est_pos.cpu().detach().numpy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train CNN models for the UJI Indoor Loc Dataset\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the UJI Indoor Loc Dataset\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "root_data = \"./\"\ndownload_dataset(\"UJIIndoorLoc\", root_data)\ndir_data = os.path.join(root_data, \"UJIIndoorLoc\")\n\nuji_train_loader = get_dataloader_ujiindoorloc(os.path.join(dir_data, \"trainingData.csv\"), ['longitude', 'latitude', 'floor', 'buildingid'], 32, True)\nn_samples_train = len(uji_train_loader.dataset)\n\nuji_test_loader = get_dataloader_ujiindoorloc(os.path.join(dir_data, \"validationData.csv\"), ['longitude', 'latitude', 'floor', 'buildingid'], 1111, False)\nn_samples_test = len(uji_test_loader.dataset)\ndataset_test = uji_test_loader.dataset\ntest_rssi, test_coord, test_area = next(iter(uji_test_loader))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train the Area (Building ID + Floor ID) classification model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ncriterion_area = torch.nn.CrossEntropyLoss().to(device)\n\ncnn_area = CNN(dim_in=520, dim_out=15, dim_embed=64, channels=[16, 64]).to(device)\noptimizer_area = Adam(cnn_area.parameters(), lr=1e-3)\n\ntrain_epochs = 10\nfor epoch in range(train_epochs):\n    total = 0\n    correct = 0\n    epoch_loss_area = 0\n\n    for batch_id, batch_data in enumerate(uji_train_loader):\n        rssi, coord, area = batch_data\n        # print(rssi)\n        total += rssi.size(0)\n        if not torch.isfinite(rssi).all():\n            raise ValueError(\"Invalid value encountered\")\n        rssi = rssi.to(device)\n        coord = coord.to(device)\n        area = area.to(device)\n\n        area_logits_pred = cnn_area(rssi)\n        loss_area = criterion_area(area_logits_pred, area)\n\n        optimizer_area.zero_grad()\n        loss_area.backward()\n        optimizer_area.step()\n\n        area_label_pred = torch.argmax(area_logits_pred, dim=1)\n        correct += area_label_pred.eq(area).sum().item()\n        epoch_loss_area += loss_area.item()\n\n    epoch_acc = 100. * (correct / total)\n    epoch_loss_area /= (batch_id + 1)\n    info = 'Epoch {}/{}: Train Accuracy = {}, Train Loss = {:.5f}'.format(epoch + 1,\n                                                                          train_epochs,\n                                                                          epoch_acc,\n                                                                          epoch_loss_area)\n    # print(info)\n\ncnn_area = cnn_area.cpu()\ncnn_area.eval()\ntest_area_logits_pred = cnn_area(test_rssi)\ntest_area_label_pred = torch.argmax(test_area_logits_pred, dim=1)\ntest_correct = test_area_label_pred.eq(test_area).sum().item()\ntest_total = test_rssi.size(0)\ntest_accuracy = test_correct / test_total\n\nprint(\"The testing accuracy of Area identification is: {}\".format(test_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train the Location (Coordinates) regression model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ncriterion_coord = torch.nn.MSELoss().to(device)\n\ncnn_coord = CNN(dim_in=520, dim_out=2, dim_embed=64, channels=[16, 64]).to(device)\noptimizer_coord = Adam(cnn_coord.parameters(), lr=5e-4)\n\ntrain_epochs = 10\nfor epoch in range(train_epochs):\n    epoch_loss_coord = 0\n\n    for batch_id, batch_data in enumerate(uji_train_loader):\n        rssi, coord, area = batch_data\n        # print(rssi)\n        if not torch.isfinite(rssi).all():\n            raise ValueError(\"Invalid value encountered\")\n        rssi = rssi.to(device)\n        coord = coord.to(device)\n        area = area.to(device)\n\n        coord_pred = cnn_coord(rssi)\n        loss_coord = criterion_coord(coord_pred, coord)\n\n        optimizer_coord.zero_grad()\n        loss_coord.backward()\n        optimizer_coord.step()\n\n        epoch_loss_coord += loss_coord.item()\n\n    epoch_loss_coord /= (batch_id + 1)\n\n    info = 'Epoch {}/{}: Train Loss (Localization Error) = {:.5f}'.format(epoch + 1,\n                                                                          train_epochs,\n                                                                          epoch_loss_coord)\n    # print(info)\n\ncnn_coord = cnn_coord.cpu()\ncnn_coord.eval()\ntest_coord_pred = cnn_coord(test_rssi)\ntest_accuracy = criterion_coord(test_coord_pred, test_coord)\n\nprint(\"The testing accuracy of coordinate localization is: {}\".format(test_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extract embeddings from pre-trained localization model (Instance: CNN for UJIIndoorLoc)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "uji_test_loader = get_dataloader_ujiindoorloc(os.path.join(dir_data, \"validationData.csv\"), ['longitude', 'latitude', 'floor', 'buildingid'], 1111, False)\nn_samples_test = len(uji_test_loader.dataset)\ndataset_test = uji_test_loader.dataset\ntest_rssi, test_coord, test_area = next(iter(uji_test_loader))\n\nfrom pysensing.rssi.models.localization.load_model import load_pretrain\n\ndevice = torch.device(\"cpu\")\n\nmodel = load_pretrain(model_name=\"CNN\", dataset_name=\"UJIIndoorLoc\", regression=False, path_model=None, device=\"cpu\")\nemb_area = rssi_embedding(rssi=test_rssi, dataset=\"UJIIndoorLoc\", model=model, device=device)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}