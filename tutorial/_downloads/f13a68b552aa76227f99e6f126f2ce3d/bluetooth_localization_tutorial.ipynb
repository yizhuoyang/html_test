{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Bluetooth Localization Tutorial\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# !pip install pysensing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is the tutoral for Bluetooth RSSI Based Localization using Fingerprinting Methods\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nfrom torch.optim import Adam, SGD\nfrom pysensing.bluetooth.datasets.wmu_ble_loc import get_dataloader_wmubleloc\nfrom pysensing.bluetooth.datasets.amazonas_indoor_env import get_dataloader_amazonasindoorenv\nfrom pysensing.bluetooth.models.localization.fingerprinting import MLP, CNN, WKNN, LSTM\nfrom pysensing.acoustic.datasets.get_dataloader import download_and_extract\nimport warnings\n\nwarnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data download links\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset_url = {\n'WMUBLELoc': 'https://pysensing.oss-ap-southeast-1.aliyuncs.com/data/ble/WMUBLELoc.zip',\n'Amazonas':'https://pysensing.oss-ap-southeast-1.aliyuncs.com/data/ble/AmazonasIndoorEnv.zip'\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the WMU BLE Localization Data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_dir = './WMUBLELoc'\n# download the dataset if the dataset have not been download\ndownload_and_extract(dataset_url['WMUBLELoc'],data_dir)\nwmu_path = \"./WMUBLELoc/iBeacon_RSSI_Labeled.csv\"\nloader_train = get_dataloader_wmubleloc(wmu_path, batch_size=32, is_train=True, train_seed=0)\nn_samples_train = len(loader_train.dataset)\nloader_test = get_dataloader_wmubleloc(wmu_path, batch_size=32, is_train=False, train_seed=0)\nn_samples_test = len(loader_test.dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Non-Trainable Method: Weighted K-Nearest Neighbors\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset_train = loader_train.dataset\ndataset_test = loader_test.dataset\n\ntrain_pos = dataset_train.ble_sets.to_numpy()[:, :2]\ntrain_ble = dataset_train.ble_sets.to_numpy()[:, -14:]\n\nsample_test_ble, sample_test_pos = dataset_test.__getitem__(0)\nsample_test_ble = sample_test_ble.detach().cpu().numpy()\n\nwknn_estimator = WKNN(train_pos, train_ble)\nwknn_est_pos = wknn_estimator(sample_test_ble, K=5)\nprint(\"Ground Truth Position: {}. Estimated Position: {}\".format(sample_test_pos.cpu().numpy(), wknn_est_pos))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Trainable Method: MLP\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nn_epochs = 10\ncriterion = torch.nn.MSELoss()\n\nmlp_estimator = MLP(dim_in=14, dim_hidden=[64, 32, 16], dim_out=2).to(device)\noptimizer = Adam(mlp_estimator.parameters(), lr=1e-3)\n\nfor epoch in range(n_epochs):\n    for batch_id, (x, y) in enumerate(loader_train):\n        x, y = x.to(device), y.to(device)\n        y_pred = mlp_estimator(x)\n        loss = criterion(y_pred, y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\nmlp_estimator.eval()\nmlp_est_pos = mlp_estimator(torch.tensor(sample_test_ble).to(device))\nprint(\"Ground Truth Position: {}. Estimated Position: {}\".format(sample_test_pos.cpu().numpy(), mlp_est_pos.cpu().detach().numpy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Trainable Method: CNN (1D)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nn_epochs = 10\ncriterion = torch.nn.MSELoss()\n\ncnn_estimator = CNN(dim_in=14, dim_out=2, dim_embed=64, channels=[16, 32]).to(device)\noptimizer = Adam(cnn_estimator.parameters(), lr=1e-3)\n\nfor epoch in range(n_epochs):\n    for batch_id, (x, y) in enumerate(loader_train):\n        if not torch.isfinite(x).all():\n            raise ValueError(\"Invalid value encountered\")\n        x, y = x.to(device), y.to(device)\n        y_pred = cnn_estimator(x)\n        if not torch.isfinite(y_pred).all():\n            print(\"Invalid value computed\")\n        loss = criterion(y_pred, y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\ncnn_estimator.eval()\ncnn_est_pos = cnn_estimator(torch.tensor(sample_test_ble).unsqueeze(0).to(device))\nprint(\"Ground Truth Position: {}. Estimated Position: {}\".format(sample_test_pos.cpu().numpy(), cnn_est_pos.cpu().detach().numpy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Trainable Method: LSTM\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nn_epochs = 10\ncriterion = torch.nn.MSELoss()\n\nlstm_estimator = LSTM(dim_in=14, dim_embed=64, dim_lstm=32, dim_out=2).to(device)\noptimizer = SGD(lstm_estimator.parameters(), lr=1e-3)\n\nfor epoch in range(n_epochs):\n    for batch_id, (x, y) in enumerate(loader_train):\n        if not torch.isfinite(x).all():\n            raise ValueError(\"Invalid value encountered\")\n        x, y = x.to(device), y.to(device)\n        y_pred = lstm_estimator(x)\n        if not torch.isfinite(y_pred).all():\n            print(\"Invalid value computed\")\n        loss = criterion(y_pred, y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\nlstm_estimator.eval()\nlstm_est_pos = lstm_estimator(torch.tensor(sample_test_ble).unsqueeze(0).to(device))\nprint(\"Ground Truth Position: {}. Estimated Position: {}\".format(sample_test_pos.cpu().numpy(), lstm_est_pos.cpu().detach().numpy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train CNN models for the Amazonas Indoor Environment Dataset\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the Amazonas Indoor Environment Dataset\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_dir = './Amazonas'\n# download the dataset if the dataset have not been download\ndownload_and_extract(dataset_url['Amazonas'],data_dir)\namazonas_path = './Amazonas/AmazonasIndoorEnv'\namazonas_train_loader = get_dataloader_amazonasindoorenv(amazonas_path, batch_size=32, is_train=True, receiver='ALL', train_seed=0)\nn_samples_train = len(amazonas_train_loader.dataset)\n\namazonas_test_loader = get_dataloader_amazonasindoorenv(amazonas_path, batch_size=32, is_train=False, receiver='ALL', train_seed=0)\nn_samples_test = len(amazonas_test_loader.dataset)\namazonas_dataset_test = amazonas_test_loader.dataset\ntest_ble, test_pos = next(iter(amazonas_test_loader))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train the Location (Coordinates) regression model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ncriterion_pos = torch.nn.MSELoss().to(device)\n\ncnn_pos = CNN(dim_in=15, dim_out=2, dim_embed=64, channels=[16, 64]).to(device)\noptimizer_pos = Adam(cnn_pos.parameters(), lr=5e-4)\n\ntrain_epochs = 10\nfor epoch in range(train_epochs):\n    epoch_loss_pos = 0\n\n    for batch_id, batch_data in enumerate(amazonas_train_loader):\n        ble, pos = batch_data\n        if not torch.isfinite(ble).all():\n            raise ValueError(\"Invalid value encountered\")\n        ble = ble.to(device)\n        pos = pos.to(device)\n\n        pos_pred = cnn_pos(ble)\n        loss_pos = criterion_pos(pos_pred, pos)\n\n        optimizer_pos.zero_grad()\n        loss_pos.backward()\n        optimizer_pos.step()\n\n        epoch_loss_pos += loss_pos.item()\n\n    epoch_loss_pos /= (batch_id + 1)\n\n    info = 'Epoch {}/{}: Train Loss (Localization Error) = {:.5f}'.format(epoch + 1,\n                                                                          train_epochs,\n                                                                          epoch_loss_pos)\n    # print(info)\n\ncnn_pos.eval()\ntest_pos_pred = cnn_pos(test_ble.to(device))\ntest_accuracy = criterion_pos(test_pos_pred, test_pos.to(device))\n\nprint(\"The testing accuracy of coordinate localization is: {}\".format(test_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extract embeddings from pre-trained localization model (Instance: CNN for UJIIndoorLoc)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "uji_test_loader = get_dataloader_amazonasindoorenv(amazonas_path, batch_size=4765, is_train=False, receiver='ALL', train_seed=0)\nn_samples_test = len(uji_test_loader.dataset)\ndataset_test = uji_test_loader.dataset\ntest_ble, test_pos = next(iter(uji_test_loader))\n\nfrom pysensing.bluetooth.models.localization.load_model import load_pretrain\n\ndevice = torch.device(\"cpu\")\nmodel = CNN(dim_in=15, dim_out=2, dim_embed=64, channels=[16, 64]).to(device)\n\nurl_pretrain = \"https://pysensing.oss-ap-southeast-1.aliyuncs.com/pretrain/ble/localization/amazonas_coord_cnn.pth\"\nmodel = load_pretrain(model, url_pretrain, device)\n\nemb_area = model.generate_embeddings(test_ble)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And that's it. We're done with our bluetooth localization tutorial tutorials. Thanks for reading.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}