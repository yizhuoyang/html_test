{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Acoustic Preprocssing.Transfrom Tutorial\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "!pip install pysensing\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this tutorial, we will be implementing a simple acoustic.preprocessing.transform\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nimport torchaudio\nimport matplotlib.pyplot as plt\nimport librosa\nimport pysensing.acoustic.preprocessing.transform as transform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the audio\nFirst, the example audio is loaded\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define the plot function\ndef plot_wave(waveform,sample_rate):\n\n    plt.figure(figsize=(10, 5))\n    plt.plot(waveform.t().numpy())\n    plt.title('Waveform')\n    plt.xlabel('Sample')\n    plt.ylabel('Amplitude')\n    plt.tight_layout()\n    plt.show()\n\ndef plot_spec(waveform,sample_rate,feature_extractor,title):\n    specgram = torch.abs(feature_extractor(waveform))\n    # specgram = transform.aplitude2db()(specgram)   \n    plt.figure(figsize=(10,5))\n    plt.imshow(specgram[0].squeeze().numpy(), aspect='auto', origin='lower', cmap='inferno', extent=[0, waveform.size(1) / sample_rate, 0, sample_rate / 2])\n    plt.title(title)\n    plt.ylim(0,5000)\n    plt.xlabel('Time (s)')\n    plt.ylabel('Frequency (Hz)')\n\n# Load the data\n# Load the data\nwaveform, sample_rate = torchaudio.load('example_data/example_audio.wav')\nplot_wave(waveform,sample_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. STFT\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "stft_trans = transform.stft(n_fft=2048,hop_length=1024)\nplot_spec(waveform,sample_rate,stft_trans,'STFT')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. ISTFT\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "stft_result = stft_trans(waveform)\nifft_trans  = transform.istft(n_fft=2048,hop_length=1024,return_complex=False)\nifft_result = ifft_trans(stft_result)\nplot_wave(ifft_result,sample_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Spectrogram\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "spectrogram_trans = transform.spectrogram(n_fft=2048,hop_length=1024,power=None)\nplot_spec(waveform,sample_rate,spectrogram_trans,'spectrogram')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Inversespectrogram\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "spectrogram_result = spectrogram_trans(waveform)\nispec_trans  = transform.inversespectrogram(n_fft=2048,hop_length=1024)\nispec_result = ispec_trans(spectrogram_result)\nplot_wave(ispec_result,sample_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Melspectrogram\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_melspectrogram(specgram, title=None, ylabel=\"freq_bin\", ax=None):\n    if ax is None:\n        _, ax = plt.subplots(1, 1,figsize=(10,5))\n    if title is not None:\n        ax.set_title(title)\n    ax.set_ylabel(ylabel)\n    ax.imshow(librosa.power_to_db(specgram), origin=\"lower\", aspect=\"auto\", interpolation=\"nearest\")\n    \nmelspectrogram_trans = transform.melspectrogram(sample_rate=sample_rate,n_fft=2048,hop_length=1024)\nmelspec              = melspectrogram_trans(waveform)[0].numpy()\nplot_melspectrogram(melspec,'melspectrogram')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And that's it. We're done with our acoustic preprocessing tutorials. Thanks for reading.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}