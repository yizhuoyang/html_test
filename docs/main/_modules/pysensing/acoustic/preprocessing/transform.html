


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>pysensing.acoustic.preprocessing.transform &mdash; Pysensing main documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/katex-math.css" type="text/css" />
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
  <!-- Google Analytics -->
  
  <!-- End Google Analytics -->
  

  
  <script src="../../../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://www.pysensing.org" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://www.pysensing.org/get-started/locally">Get Started</a>
          </li>

          <!-- <li> -->
          <li>
            <a href="https://www.pysensing.org/tutorial/">Tutorials</a>
          </li>

          <!-- <li> -->
          <li>
            <a href="https://www.pysensing.org/docs">Doc</a>
          </li>

          <li>
            <a href="https://www.pysensing.org/about-us">About Us</a>
          </li>

          <li>
            <a href="https://github.com/pysensing/pysensing">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  0.1.0
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../acoustic/Acoustic.html">Acoustic</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../bluetooth/bluetooth.html">BLUETOOTH</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../csi/csi.html">CSI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../intraoral_scan/intraoral_scan.html">intraoral_scan</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../mmwave_PC/mmwave_PC.html">mmwave_PC</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../mmwave_raw/mmwave_raw.html">mmwave_raw</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../rssi/rssi.html">RSSI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../uwb/uwb.html">UWB</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../../../index.html">Module code</a> &gt;</li>
        
      <li>pysensing.acoustic.preprocessing.transform</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for pysensing.acoustic.preprocessing.transform</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchaudio</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">Tensor</span>




<div class="viewcode-block" id="stft"><a class="viewcode-back" href="../../../../acoustic/generated/preprocessing/transform/pysensing.acoustic.preprocessing.transform.stft.html#pysensing.acoustic.preprocessing.transform.stft">[docs]</a><span class="k">class</span> <span class="nc">stft</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Transform the input audio data into its Short-Time Fourier Transform (STFT).</span>

<span class="sd">    The STFT of a signal is defined as:</span>

<span class="sd">    .. math::</span>
<span class="sd">        X(m, \omega) = \sum_{n=0}^{N-1} x(n) \cdot w(n - m \cdot \text{hop\_length}) \cdot e^{-j\omega n}</span>

<span class="sd">    - :math:`X(m, \omega)`: The STFT of the signal, representing the complex magnitude of the signal at time frame :math:`m` and frequency :math:`\omega`.</span>
<span class="sd">    - :math:`x(n)`: The input signal at time sample :math:`n`.</span>
<span class="sd">    - :math:`w(n - m \cdot \text{hop\_length})`: The window function applied to the signal, centered at the current frame :math:`m` and offset by :math:`\text{hop\_length}`.</span>
<span class="sd">    - :math:`\text{hop\_length}`: The step size between consecutive frames, determining the time resolution of the STFT.</span>
<span class="sd">    - :math:`e^{-j\omega n}`: The complex exponential function representing the basis functions of the Fourier transform at frequency :math:`\omega` and time sample :math:`n`.</span>

<span class="sd">    Args:</span>
<span class="sd">        n_fft (int): The size of the Fourier transform. This determines the number of frequency bins used in the STFT.</span>
<span class="sd">        hop_length (int, optional): The distance between neighboring sliding window frames.</span>
<span class="sd">            frames. Default: ``None`` (treated as equal to ``floor(n_fft / 4)``)</span>
<span class="sd">        win_length (int, optional): The size of the window frame and STFT filter.</span>
<span class="sd">            Default: ``None``  (treated as equal to :attr:`n_fft`)</span>
<span class="sd">        window (Tensor, optional): An optional window function. The shape must be 1D and `&lt;= n_fft`.</span>
<span class="sd">            Default: ``None`` (treated as window of all :math:`1` s)</span>
<span class="sd">        center (bool, optional): Whether to pad :attr:`input` on both sides so</span>
<span class="sd">            that the :math:`t`-th frame is centered at time :math:`t \times \text{hop\_length}`.</span>
<span class="sd">            Default: ``True``</span>
<span class="sd">        pad_mode (str, optional): Controls the padding method used when center is True. </span>
<span class="sd">            Default: ``&quot;reflect&quot;``</span>
<span class="sd">        normalized (bool, optional): Indicates whether to return normalized STFT results.</span>
<span class="sd">             Default: ``False``</span>
<span class="sd">        onesided (bool, optional): Indicates whether to return only half of the results to avoid redundancy for real inputs.</span>
<span class="sd">            Default: ``True`` for real :attr:`input` and :attr:`window`, ``False`` otherwise.</span>
<span class="sd">        return_complex (bool, optional): Indicates whether to return a complex tensor, </span>
<span class="sd">            or a real tensor with an extra last dimension for the real and imaginary components.</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; import pysensing.acoustic.preprocessing.transform as T</span>
<span class="sd">        &gt;&gt;&gt; stft_trans = T.stft(n_fft=400)</span>
<span class="sd">        &gt;&gt;&gt; spectrogram       = stft_trans(waveform)</span>

<span class="sd">    Note:</span>
<span class="sd">        The implementation is based on torch.stft.</span>
<span class="sd">        </span>
<span class="sd">    Reference: </span>
<span class="sd">        https://pytorch.org/docs/stable/generated/torch.stft.html   </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">n_fft</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">400</span><span class="p">,</span> 
        <span class="n">hop_length</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">win_length</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 
        <span class="n">window</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">center</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> 
        <span class="n">pad_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;reflect&#39;</span><span class="p">,</span> 
        <span class="n">normalized</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">onesided</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_complex</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">stft</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_fft</span> <span class="o">=</span> <span class="n">n_fft</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">win_length</span> <span class="o">=</span> <span class="n">win_length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hop_length</span> <span class="o">=</span> <span class="n">hop_length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">window</span> <span class="o">=</span> <span class="n">window</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">center</span> <span class="o">=</span> <span class="n">center</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pad_mode</span> <span class="o">=</span> <span class="n">pad_mode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalized</span> <span class="o">=</span> <span class="n">normalized</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">onesided</span> <span class="o">=</span> <span class="n">onesided</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_complex</span> <span class="o">=</span> <span class="n">return_complex</span>

<div class="viewcode-block" id="stft.forward"><a class="viewcode-back" href="../../../../acoustic/generated/preprocessing/transform/pysensing.acoustic.preprocessing.transform.stft.html#pysensing.acoustic.preprocessing.transform.stft.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">waveform</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            waveform (Tensor): the input tensor of shape `(B?, L)` where `B?` is an optional batch dimension</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">            Tensor: A tensor containing the STFT result with shape `(B?, N, T, C?)` where</span>
<span class="sd">            - `B?` is an optional batch dimension from the input.</span>
<span class="sd">            - `N` is the number of frequency samples.</span>
<span class="sd">            - `T` is the number of frames.</span>
<span class="sd">            - `C?` is an optional length-2 dimension of real and imaginary components.</span>
<span class="sd">    &quot;&quot;&quot;</span>
        
        <span class="n">stft_result</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stft</span><span class="p">(</span>
            <span class="n">waveform</span><span class="p">,</span>
            <span class="n">n_fft</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_fft</span><span class="p">,</span>
            <span class="n">win_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">win_length</span><span class="p">,</span>
            <span class="n">hop_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hop_length</span><span class="p">,</span>
            <span class="n">window</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">window</span><span class="p">,</span>
            <span class="n">center</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">center</span><span class="p">,</span>
            <span class="n">pad_mode</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pad_mode</span><span class="p">,</span>
            <span class="n">normalized</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalized</span><span class="p">,</span>
            <span class="n">onesided</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">onesided</span><span class="p">,</span>
            <span class="n">return_complex</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_complex</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">stft_result</span></div></div>

<div class="viewcode-block" id="istft"><a class="viewcode-back" href="../../../../acoustic/generated/preprocessing/transform/pysensing.acoustic.preprocessing.transform.istft.html#pysensing.acoustic.preprocessing.transform.istft">[docs]</a><span class="k">class</span> <span class="nc">istft</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Transform the STFT of a signal back into its time-domain representation using the Inverse Short-Time Fourier Transform (ISTFT).</span>

<span class="sd">    The ISTFT of a signal is defined as:</span>

<span class="sd">    .. math::</span>
<span class="sd">        x(n) = \frac{\sum_{m=0}^{M-1} X(m, \omega) \cdot w(n - m \cdot \text{hop\_length}) \cdot e^{j\omega n}}{\sum_{m=0}^{M-1} w^2(n - m \cdot \text{hop\_length})}</span>
<span class="sd">    </span>
<span class="sd">    - :math:`x(n)`: The time-domain signal at sample :math:`n`, reconstructed from the STFT.</span>
<span class="sd">    - :math:`X(m, \omega)`: The STFT of the signal, representing the complex magnitude at time frame :math:`m` and frequency :math:`\omega`.</span>
<span class="sd">    - :math:`w(n - m \cdot \text{hop\_length})`: The window function applied to the signal, centered at the current frame :math:`m` and offset by :math:`\text{hop\_length}`.</span>
<span class="sd">    - :math:`\text{hop\_length}`: The step size between consecutive frames, determining the time resolution of the ISTFT.</span>
<span class="sd">    - :math:`e^{j\omega n}`: The complex exponential function representing the basis functions of the inverse Fourier transform at frequency :math:`\omega` and time sample :math:`n`.</span>
<span class="sd">    - :math:`\sum_{m=0}^{M-1} w^2(n - m \cdot \text{hop\_length})`: The normalization factor accounting for the overlap of the window function.</span>

<span class="sd">    Args:</span>
<span class="sd">        n_fft (int): Size of Fourier transform.</span>
<span class="sd">        hop_length (Optional[int]): The distance between neighboring sliding window frames.</span>
<span class="sd">            (Default: ``n_fft // 4``)</span>
<span class="sd">        win_length (Optional[int]): The size of window frame and STFT filter. (Default: ``n_fft``)</span>
<span class="sd">        window (Optional[torch.Tensor]): The optional window function.</span>
<span class="sd">            Shape must be 1d and `&lt;= n_fft`.</span>
<span class="sd">            (Default: ``torch.ones(win_length)``)</span>
<span class="sd">        center (bool): Whether :attr:`input` was padded on both sides so that the :math:`t`-th frame is</span>
<span class="sd">            centered at time :math:`t \times \text{hop\_length}`.</span>
<span class="sd">            (Default: ``True``)</span>
<span class="sd">        normalized (bool): Whether the STFT was normalized. (Default: ``False``)</span>
<span class="sd">        onesided (Optional[bool]): Whether the STFT was onesided.</span>
<span class="sd">            (Default: ``True`` if `n_fft != fft_size` in the input size)</span>
<span class="sd">        length (Optional[int]): The amount to trim the signal by (i.e. the</span>
<span class="sd">            original signal length). Defaults to `(T - 1) * hop_length` for</span>
<span class="sd">            centered STFT, or `n_fft + (T - 1) * hop_length` otherwise, where `T`</span>
<span class="sd">            is the number of input frames.</span>
<span class="sd">        return_complex (Optional[bool]): Whether the output should be complex, or if the input should be</span>
<span class="sd">            assumed to derive from a real signal and window.</span>
<span class="sd">            Note that this is incompatible with ``onesided=True``.</span>
<span class="sd">            (Default: ``False``)</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; import pysensing.acoustic.preprocessing.transform as T</span>
<span class="sd">        &gt;&gt;&gt; istft_trans = T.istft(n_fft=400)</span>
<span class="sd">        &gt;&gt;&gt; waveform = istft_trans(input)</span>

<span class="sd">    Note:</span>
<span class="sd">        The implementation is based on torch.istft.</span>

<span class="sd">    Reference:</span>
<span class="sd">        https://pytorch.org/docs/stable/generated/torch.istft.html   </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">n_fft</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">400</span><span class="p">,</span> 
        <span class="n">hop_length</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">win_length</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> 

        <span class="n">window</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">center</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> 
        <span class="n">normalized</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">onesided</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">length</span><span class="p">:</span> <span class="p">(</span><span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">return_complex</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">istft</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_fft</span> <span class="o">=</span> <span class="n">n_fft</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">win_length</span> <span class="o">=</span> <span class="n">win_length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hop_length</span> <span class="o">=</span> <span class="n">hop_length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">window</span> <span class="o">=</span> <span class="n">window</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">center</span> <span class="o">=</span> <span class="n">center</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalized</span> <span class="o">=</span> <span class="n">normalized</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">onesided</span> <span class="o">=</span> <span class="n">onesided</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">length</span> <span class="o">=</span> <span class="n">length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">return_complex</span> <span class="o">=</span> <span class="n">return_complex</span>

<div class="viewcode-block" id="istft.forward"><a class="viewcode-back" href="../../../../acoustic/generated/preprocessing/transform/pysensing.acoustic.preprocessing.transform.istft.html#pysensing.acoustic.preprocessing.transform.istft.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            input (Tensor): The input tensor. </span>
<span class="sd">            output. That is a complex tensor of shape `(B?, N, T)` where</span>
<span class="sd">            - `B?` is an optional batch dimension.</span>
<span class="sd">            - `N` is the number of frequency samples.</span>
<span class="sd">            - `T` is the number of frames.</span>
<span class="sd">            </span>
<span class="sd">        Returns:</span>
<span class="sd">            Tensor: Least squares estimation of the original signal of shape `(B?, length)` where</span>
<span class="sd">                `B?` is an optional batch dimension from the input tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">istft_result</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">istft</span><span class="p">(</span>
            <span class="nb">input</span><span class="p">,</span>
            <span class="n">n_fft</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_fft</span><span class="p">,</span>
            <span class="n">win_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">win_length</span><span class="p">,</span>
            <span class="n">hop_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hop_length</span><span class="p">,</span>
            <span class="n">window</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">window</span><span class="p">,</span>
            <span class="n">center</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">center</span><span class="p">,</span>
            <span class="n">normalized</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">normalized</span><span class="p">,</span>
            <span class="n">onesided</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">onesided</span><span class="p">,</span>
            <span class="n">length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">length</span><span class="p">,</span>
            <span class="n">return_complex</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_complex</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">istft_result</span></div></div>

<div class="viewcode-block" id="spectrogram"><a class="viewcode-back" href="../../../../acoustic/generated/preprocessing/transform/pysensing.acoustic.preprocessing.transform.spectrogram.html#pysensing.acoustic.preprocessing.transform.spectrogram">[docs]</a><span class="k">class</span> <span class="nc">spectrogram</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convert the input audio data into a spectrogram. If the input is multi-channel audio, it should be in channel-first format.</span>

<span class="sd">    Args:</span>
<span class="sd">        waveform (Tensor): Tensor of audio data with dimensions `(..., time)`.</span>
<span class="sd">        pad (int): Amount of padding to apply to both sides of the signal.</span>
<span class="sd">        window (Tensor): Window tensor to be applied to each frame.</span>
<span class="sd">        n_fft (int): Size of the FFT.</span>
<span class="sd">        hop_length (int): Number of samples between successive STFT windows.</span>
<span class="sd">        win_length (int): Size of each window.</span>
<span class="sd">        power (float or None): Exponent for the magnitude spectrogram (must be &gt; 0). For example, 1 for magnitude, 2 for power. If None, the complex spectrum is returned.</span>
<span class="sd">        normalized (bool or str): Whether to normalize by magnitude after STFT. If a string, valid choices are ``&quot;window&quot;`` and ``&quot;frame_length&quot;``. If True, it maps to ``&quot;window&quot;``. When normalized on ``&quot;window&quot;``, the waveform is normalized by the window&#39;s L2 energy. If normalized on ``&quot;frame_length&quot;``, it is normalized by dividing by :math:`(\text{frame\_length})^{0.5}`.</span>
<span class="sd">        center (bool, optional): Whether to pad the waveform on both sides so that the :math:`t`-th frame is centered at time :math:`t \times \text{hop\_length}`. Default is True.</span>
<span class="sd">        pad_mode (str, optional): Method used for padding when `center` is True. Default is ``&quot;reflect&quot;``.</span>
<span class="sd">        onesided (bool, optional): Whether to return only half of the results to avoid redundancy. Default is True.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor: Dimension `(..., freq, time)`, freq is</span>
<span class="sd">        ``n_fft // 2 + 1`` and ``n_fft`` is the number of</span>
<span class="sd">        Fourier bins, and time is the number of window hops (n_frame).</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; import pysensing.acoustic.preprocessing.transform as T</span>
<span class="sd">        &gt;&gt;&gt; spectorgram_trans = T.spectrogram(n_fft=400)</span>
<span class="sd">        &gt;&gt;&gt; spectrogram       = spectorgram_trans(waveform)</span>

<span class="sd">    Note:</span>
<span class="sd">        The implementation is based on torchaudio.transforms.Spectrogram.</span>

<span class="sd">    Reference: </span>
<span class="sd">        https://pytorch.org/audio/stable/generated/torchaudio.functional.spectrogram.html?highlight=spectrogram#torchaudio.functional.spectrogram</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">n_fft</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">400</span><span class="p">,</span>
        <span class="n">win_length</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">hop_length</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">pad</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">window_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">hann_window</span><span class="p">,</span>
        <span class="n">power</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="mf">2.0</span><span class="p">,</span>
        <span class="n">normalized</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">bool</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">wkwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">center</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">pad_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;reflect&quot;</span><span class="p">,</span>
        <span class="n">onesided</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">return_complex</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">spectrogram</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transformation</span> <span class="o">=</span> <span class="n">torchaudio</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Spectrogram</span><span class="p">(</span>
            <span class="n">n_fft</span> <span class="o">=</span> <span class="n">n_fft</span><span class="p">,</span>
            <span class="n">win_length</span> <span class="o">=</span> <span class="n">win_length</span><span class="p">,</span>
            <span class="n">hop_length</span> <span class="o">=</span> <span class="n">hop_length</span><span class="p">,</span>
            <span class="n">pad</span> <span class="o">=</span> <span class="n">pad</span><span class="p">,</span>
            <span class="n">window_fn</span> <span class="o">=</span> <span class="n">window_fn</span><span class="p">,</span>
            <span class="n">power</span> <span class="o">=</span> <span class="n">power</span><span class="p">,</span>
            <span class="n">normalized</span> <span class="o">=</span> <span class="n">normalized</span><span class="p">,</span>
            <span class="n">wkwargs</span> <span class="o">=</span> <span class="n">wkwargs</span><span class="p">,</span>
            <span class="n">center</span> <span class="o">=</span> <span class="n">center</span><span class="p">,</span>
            <span class="n">pad_mode</span> <span class="o">=</span> <span class="n">pad_mode</span><span class="p">,</span>
            <span class="n">onesided</span> <span class="o">=</span> <span class="n">onesided</span><span class="p">,</span>
            <span class="n">return_complex</span> <span class="o">=</span> <span class="n">return_complex</span>
        <span class="p">)</span>


<div class="viewcode-block" id="spectrogram.forward"><a class="viewcode-back" href="../../../../acoustic/generated/preprocessing/transform/pysensing.acoustic.preprocessing.transform.spectrogram.html#pysensing.acoustic.preprocessing.transform.spectrogram.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">waveform</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            waveform (Tensor): Tensor of audio of dimension (..., time).</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor: Dimension (..., freq, time), where freq is</span>
<span class="sd">            ``n_fft // 2 + 1`` where ``n_fft`` is the number of</span>
<span class="sd">            Fourier bins, and time is the number of window hops (n_frame).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">spectrogram_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformation</span><span class="p">(</span><span class="n">waveform</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">spectrogram_result</span></div></div>

<div class="viewcode-block" id="inversespectrogram"><a class="viewcode-back" href="../../../../acoustic/generated/preprocessing/transform/pysensing.acoustic.preprocessing.transform.inversespectrogram.html#pysensing.acoustic.preprocessing.transform.inversespectrogram">[docs]</a><span class="k">class</span> <span class="nc">inversespectrogram</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Transform the input spectrogram to a raw audio data. If the input is a multiple-channel audio, need to be channel first.</span>

<span class="sd">    Args:</span>
<span class="sd">        n_fft (int, optional): Size of FFT, creating ``n_fft // 2 + 1`` bins. Default is 400.</span>
<span class="sd">        win_length (int or None, optional): Window size. Default is ``n_fft``.</span>
<span class="sd">        hop_length (int or None, optional): Length of hop between STFT windows. Default is ``win_length // 2``.</span>
<span class="sd">        pad (int, optional): Two-sided padding of the signal. Default is 0.</span>
<span class="sd">        window_fn (Callable[..., Tensor], optional): Function to create a window tensor applied to each frame. Default is ``torch.hann_window``.</span>
<span class="sd">        normalized (bool or str, optional): Indicates if the STFT output was normalized by magnitude. If str, choices are ``&quot;window&quot;`` and ``&quot;frame_length&quot;``. ``True`` maps to ``&quot;window&quot;``. Default is False.</span>
<span class="sd">        wkwargs (dict or None, optional): Arguments for the window function. Default is None.</span>
<span class="sd">        center (bool, optional): Indicates if the spectrogram signal was padded on both sides so that the :math:`t`-th frame is centered at time :math:`t \times \text{hop\_length}`. Default is True.</span>
<span class="sd">        pad_mode (str, optional): Controls the padding method used when :attr:`center` is True. Default is ``&quot;reflect&quot;``.</span>
<span class="sd">        onesided (bool, optional): Indicates if the spectrogram was used to return half of the results to avoid redundancy. Default is True.</span>
<span class="sd">        length (int or None, optional): The output length of the waveform.</span>


<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; import pysensing.acoustic.preprocessing.transform as T</span>
<span class="sd">        &gt;&gt;&gt; inversespectorgram_trans = T.inversespectrogram(n_fft=400)</span>
<span class="sd">        &gt;&gt;&gt; waveform       = inversespectorgram_trans(input)</span>

<span class="sd">    Note:</span>
<span class="sd">        The implementation is based on torchaudio.transforms.InverseSpectrogram.</span>

<span class="sd">    Reference: </span>
<span class="sd">        https://pytorch.org/audio/stable/generated/torchaudio.transforms.InverseSpectrogram.html#torchaudio.transforms.InverseSpectrogram</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">n_fft</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">400</span><span class="p">,</span>
        <span class="n">win_length</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">hop_length</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">pad</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">window_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">hann_window</span><span class="p">,</span>
        <span class="n">normalized</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">bool</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">wkwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">center</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">pad_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;reflect&quot;</span><span class="p">,</span>
        <span class="n">onesided</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">length</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">inversespectrogram</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">length</span> <span class="o">=</span> <span class="n">length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transformation</span> <span class="o">=</span> <span class="n">torchaudio</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">InverseSpectrogram</span><span class="p">(</span>
            <span class="n">n_fft</span> <span class="o">=</span> <span class="n">n_fft</span><span class="p">,</span>
            <span class="n">win_length</span> <span class="o">=</span> <span class="n">win_length</span><span class="p">,</span>
            <span class="n">hop_length</span> <span class="o">=</span> <span class="n">hop_length</span><span class="p">,</span>
            <span class="n">pad</span> <span class="o">=</span> <span class="n">pad</span><span class="p">,</span>
            <span class="n">window_fn</span> <span class="o">=</span> <span class="n">window_fn</span><span class="p">,</span>
            <span class="n">normalized</span> <span class="o">=</span> <span class="n">normalized</span><span class="p">,</span>
            <span class="n">wkwargs</span> <span class="o">=</span> <span class="n">wkwargs</span><span class="p">,</span>
            <span class="n">center</span> <span class="o">=</span> <span class="n">center</span><span class="p">,</span>
            <span class="n">pad_mode</span> <span class="o">=</span> <span class="n">pad_mode</span><span class="p">,</span>
            <span class="n">onesided</span> <span class="o">=</span> <span class="n">onesided</span><span class="p">,</span>
        <span class="p">)</span>


<div class="viewcode-block" id="inversespectrogram.forward"><a class="viewcode-back" href="../../../../acoustic/generated/preprocessing/transform/pysensing.acoustic.preprocessing.transform.inversespectrogram.html#pysensing.acoustic.preprocessing.transform.inversespectrogram.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">spectrogram</span> <span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            spectrogram (Tensor): Complex tensor of audio of dimension (..., freq, time).</span>
<span class="sd">        Returns:</span>
<span class="sd">            Tensor: Dimension (..., time), Least squares estimation of the original signal.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">inversespectrogram_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformation</span><span class="p">(</span><span class="n">spectrogram</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">length</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">inversespectrogram_result</span>    </div></div>

<div class="viewcode-block" id="melspectrogram"><a class="viewcode-back" href="../../../../acoustic/generated/preprocessing/transform/pysensing.acoustic.preprocessing.transform.melspectrogram.html#pysensing.acoustic.preprocessing.transform.melspectrogram">[docs]</a><span class="k">class</span> <span class="nc">melspectrogram</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Transform the input audio data into a MelSpectrogram. If the input is multi-channel audio, it needs to be channel-first.</span>

<span class="sd">    Args:</span>
<span class="sd">        sample_rate (int, optional): Sample rate of the audio signal. Default is 16000.</span>
<span class="sd">        n_fft (int, optional): Size of the FFT, creating ``n_fft // 2 + 1`` bins. Default is 400.</span>
<span class="sd">        win_length (int or None, optional): Window size. Default is ``n_fft``.</span>
<span class="sd">        hop_length (int or None, optional): Length of the hop between STFT windows. Default is ``win_length // 2``.</span>
<span class="sd">        f_min (float, optional): Minimum frequency. Default is 0.0.</span>
<span class="sd">        f_max (float or None, optional): Maximum frequency. Default is None.</span>
<span class="sd">        pad (int, optional): Amount of padding applied to both sides of the signal. Default is 0.</span>
<span class="sd">        n_mels (int, optional): Number of Mel filterbanks. Default is 128.</span>
<span class="sd">        window_fn (Callable[..., Tensor], optional): Function to create a window tensor that is applied to each frame. Default is ``torch.hann_window``.</span>
<span class="sd">        power (float, optional): Exponent for the magnitude spectrogram (must be &gt; 0). For example, 1 for magnitude, 2 for power. Default is 2.</span>
<span class="sd">        normalized (bool, optional): Whether to normalize by magnitude after STFT. Default is False.</span>
<span class="sd">        wkwargs (Dict[..., ...] or None, optional): Arguments for the window function. Default is None.</span>
<span class="sd">        center (bool, optional): Whether to pad the waveform on both sides so that the :math:`t`-th frame is centered at time :math:`t \times \text{hop\_length}`. Default is True.</span>
<span class="sd">        pad_mode (str, optional): Method used for padding when `center` is True. Default is ``reflect``.</span>
<span class="sd">        onesided: Deprecated and unused.</span>
<span class="sd">        norm (str or None, optional): If &quot;slaney&quot;, divide the triangular Mel weights by the width of the Mel band (area normalization). Default is None.</span>
<span class="sd">        mel_scale (str, optional): Scale to use: ``htk`` or ``slaney``. Default is ``htk``.</span>
<span class="sd">        </span>
<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; import pysensing.acoustic.preprocessing.transform as T</span>
<span class="sd">        &gt;&gt;&gt; melspectrogram_trans = T.melspectrogram(sample_rate=44100,n_fft=400)</span>
<span class="sd">        &gt;&gt;&gt; melspectrogram       = melspectorgram_trans(waveform)</span>

<span class="sd">    Note:</span>
<span class="sd">        The implementation is based on torchaudio.transforms.MelSpectrogram.</span>

<span class="sd">    Reference: </span>
<span class="sd">        https://pytorch.org/audio/stable/generated/torchaudio.transforms.MelSpectrogram.html?highlight=melspectrogram#torchaudio.transforms.MelSpectrogram</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">sample_rate</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">16000</span><span class="p">,</span>
        <span class="n">n_fft</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">400</span><span class="p">,</span>
        <span class="n">win_length</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">hop_length</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">f_min</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="n">f_max</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">pad</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">n_mels</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span>
        <span class="n">window_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">hann_window</span><span class="p">,</span>
        <span class="n">power</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">2.0</span><span class="p">,</span>
        <span class="n">normalized</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">wkwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">center</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">pad_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;reflect&quot;</span><span class="p">,</span>
        <span class="n">onesided</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">norm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">mel_scale</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;htk&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">melspectrogram</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transformation</span> <span class="o">=</span> <span class="n">torchaudio</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">MelSpectrogram</span><span class="p">(</span>
            <span class="n">sample_rate</span> <span class="o">=</span> <span class="n">sample_rate</span><span class="p">,</span>
            <span class="n">n_fft</span> <span class="o">=</span> <span class="n">n_fft</span><span class="p">,</span>
            <span class="n">win_length</span> <span class="o">=</span> <span class="n">win_length</span><span class="p">,</span>
            <span class="n">hop_length</span> <span class="o">=</span> <span class="n">hop_length</span><span class="p">,</span>
            <span class="n">f_min</span> <span class="o">=</span> <span class="n">f_min</span><span class="p">,</span>
            <span class="n">f_max</span> <span class="o">=</span> <span class="n">f_max</span><span class="p">,</span>
            <span class="n">pad</span> <span class="o">=</span> <span class="n">pad</span><span class="p">,</span>
            <span class="n">n_mels</span> <span class="o">=</span> <span class="n">n_mels</span><span class="p">,</span>
            <span class="n">window_fn</span> <span class="o">=</span> <span class="n">window_fn</span><span class="p">,</span>
            <span class="n">power</span> <span class="o">=</span> <span class="n">power</span><span class="p">,</span>
            <span class="n">normalized</span> <span class="o">=</span> <span class="n">normalized</span><span class="p">,</span>
            <span class="n">wkwargs</span> <span class="o">=</span> <span class="n">wkwargs</span><span class="p">,</span>
            <span class="n">center</span> <span class="o">=</span> <span class="n">center</span><span class="p">,</span>
            <span class="n">pad_mode</span> <span class="o">=</span> <span class="n">pad_mode</span><span class="p">,</span>
            <span class="n">onesided</span> <span class="o">=</span> <span class="n">onesided</span><span class="p">,</span>
            <span class="n">norm</span> <span class="o">=</span> <span class="n">norm</span><span class="p">,</span>
            <span class="n">mel_scale</span> <span class="o">=</span> <span class="n">mel_scale</span>
        <span class="p">)</span>

<div class="viewcode-block" id="melspectrogram.forward"><a class="viewcode-back" href="../../../../acoustic/generated/preprocessing/transform/pysensing.acoustic.preprocessing.transform.melspectrogram.html#pysensing.acoustic.preprocessing.transform.melspectrogram.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">waveform</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            waveform (Tensor): Tensor of audio of dimension (..., time).</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor: Mel frequency spectrogram of size (..., ``n_mels``, time).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">melspectrogram_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformation</span><span class="p">(</span><span class="n">waveform</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">melspectrogram_result</span></div></div>

<div class="viewcode-block" id="mfcc"><a class="viewcode-back" href="../../../../acoustic/generated/preprocessing/transform/pysensing.acoustic.preprocessing.transform.mfcc.html#pysensing.acoustic.preprocessing.transform.mfcc">[docs]</a><span class="k">class</span> <span class="nc">mfcc</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Transform the input audio data to a mfcc. If the input is a multiple-channel audio, need to be channel first.</span>

<span class="sd">    Args:</span>
<span class="sd">        sample_rate (int, optional): The sample rate of the audio signal. Default is 16000.</span>
<span class="sd">        n_mfcc (int, optional): The number of MFCC coefficients to compute. Default is 40.</span>
<span class="sd">        dct_type (int, optional): The type of Discrete Cosine Transform (DCT) to apply. Default is 2.</span>
<span class="sd">        norm (str, optional): The normalization to apply to the DCT. Default is &quot;ortho&quot;.</span>
<span class="sd">        log_mels (bool, optional): If True, use log-mel spectrograms instead of dB-scaled spectrograms. Default is False.</span>
<span class="sd">        melkwargs (dict or None, optional): Additional parameters for the MelSpectrogram computation. Default is None.</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; import pysensing.acoustic.preprocessing.transform as T</span>
<span class="sd">        &gt;&gt;&gt; mfcc_trans = T.mfcc(n_fft=400)</span>
<span class="sd">        &gt;&gt;&gt; mfcc       = mfcc_trans(waveform)</span>

<span class="sd">    Note:</span>
<span class="sd">        The implementation is based on torchaudio.transforms.MFCC.  </span>

<span class="sd">    Reference: </span>
<span class="sd">        https://pytorch.org/audio/stable/generated/torchaudio.transforms.MFCC.html?highlight=mfcc#torchaudio.transforms.MFCC</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">sample_rate</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">16000</span><span class="p">,</span>
        <span class="n">n_mfcc</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">40</span><span class="p">,</span>
        <span class="n">dct_type</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
        <span class="n">norm</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;ortho&quot;</span><span class="p">,</span>
        <span class="n">log_mels</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">melkwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">mfcc</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transformation</span> <span class="o">=</span> <span class="n">torchaudio</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">MFCC</span><span class="p">(</span>
            <span class="n">sample_rate</span> <span class="o">=</span> <span class="n">sample_rate</span><span class="p">,</span>
            <span class="n">n_mfcc</span> <span class="o">=</span> <span class="n">n_mfcc</span><span class="p">,</span>
            <span class="n">dct_type</span> <span class="o">=</span> <span class="n">dct_type</span><span class="p">,</span>
            <span class="n">norm</span> <span class="o">=</span> <span class="n">norm</span><span class="p">,</span>
            <span class="n">log_mels</span> <span class="o">=</span> <span class="n">log_mels</span><span class="p">,</span>
            <span class="n">melkwargs</span> <span class="o">=</span> <span class="n">melkwargs</span>
        <span class="p">)</span>

<div class="viewcode-block" id="mfcc.forward"><a class="viewcode-back" href="../../../../acoustic/generated/preprocessing/transform/pysensing.acoustic.preprocessing.transform.mfcc.html#pysensing.acoustic.preprocessing.transform.mfcc.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">waveform</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            waveform (Tensor): Tensor of audio of dimension (..., time).</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor: specgram_mel_db of size (..., ``n_mfcc``, time).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">mfcc_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformation</span><span class="p">(</span><span class="n">waveform</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">mfcc_result</span></div></div>

<div class="viewcode-block" id="GCC"><a class="viewcode-back" href="../../../../acoustic/generated/preprocessing/transform/pysensing.acoustic.preprocessing.transform.GCC.html#pysensing.acoustic.preprocessing.transform.GCC">[docs]</a><span class="k">class</span> <span class="nc">GCC</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Transform the input multi-channel audio data to a Generalized Cross-Correlation (GCC) representation.</span>

<span class="sd">    The GCC of two signals is defined as:</span>

<span class="sd">    .. math::</span>
<span class="sd">        R_{x_1 x_2}(\tau) = \mathcal{F}^{-1} \left\{ \frac{X_1(\omega) X_2^*(\omega)}{G(\omega) + \epsilon} \right\}</span>

<span class="sd">    - :math:`R_{x_1 x_2}(\tau)`: The GCC function of the two signals.</span>
<span class="sd">    - :math:`\mathcal{F}^{-1}`: The inverse Fourier transform.</span>
<span class="sd">    - :math:`X_1(\omega)`: The Fourier transform of the first signal.</span>
<span class="sd">    - :math:`X_2^*(\omega)`: The complex conjugate of the Fourier transform of the second signal.</span>
<span class="sd">    - :math:`G(\omega)`: The filter applied in the GCC computation, which varies based on the chosen type:</span>
<span class="sd">    - &#39;cc&#39;: :math:`G(\omega) = 1`</span>
<span class="sd">    - &#39;phat&#39;: :math:`G(\omega) = |X_1(\omega) X_2^*(\omega)|`</span>
<span class="sd">    - &#39;roth&#39;: :math:`G(\omega) = |X_1(\omega)|^2`</span>
<span class="sd">    - &#39;scot&#39;: :math:`G(\omega) = |X_1(\omega) X_2^*(\omega)|^{1/2}`</span>
<span class="sd">    - :math:`\epsilon`: A small value to avoid division by zero.</span>

<span class="sd">    Args:</span>
<span class="sd">        dim (int): The dimension of the input signal. Default is 2 (channels, samples).</span>
<span class="sd">        filt (str): The type of GCC to apply. Supported values are [&#39;cc&#39;, &#39;phat&#39;, &#39;roth&#39;, &#39;scot&#39;]. Default is &#39;phat&#39;.</span>
<span class="sd">        epsilon (float): A small value to avoid division by zero. Default is 0.001.</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; import pysensing.acoustic.preprocessing.transform as T</span>
<span class="sd">        &gt;&gt;&gt; GCC_trans = T.GCC()</span>
<span class="sd">        &gt;&gt;&gt; GCC = GCC_trans(waveform, waveform2)</span>

<span class="sd">    Reference:</span>
<span class="sd">        https://github.com/axeber01/ngcc/blob/main/model.py</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">filt</span><span class="p">:</span><span class="nb">str</span><span class="o">=</span><span class="s1">&#39;phat&#39;</span><span class="p">,</span>
        <span class="n">dim</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>  
        <span class="n">epsilon</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,):</span>
        
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="n">dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">filt</span> <span class="o">=</span> <span class="n">filt</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="n">epsilon</span>

<div class="viewcode-block" id="GCC.forward"><a class="viewcode-back" href="../../../../acoustic/generated/preprocessing/transform/pysensing.acoustic.preprocessing.transform.GCC.html#pysensing.acoustic.preprocessing.transform.GCC.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            x (Tensor): the input of the first waveform</span>
<span class="sd">            y (Tensor): the input of the second waveform</span>
<span class="sd">        Returns:</span>
<span class="sd">            Tensor: the GCC result</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1"># Generalized Cross Correlation Phase Transform</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">rfft</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
        <span class="n">Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">rfft</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
        <span class="n">Gxy</span> <span class="o">=</span> <span class="n">X</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">conj</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">filt</span> <span class="o">==</span> <span class="s1">&#39;phat&#39;</span><span class="p">:</span>
            <span class="n">phi</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">Gxy</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">)</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">filt</span> <span class="o">==</span> <span class="s1">&#39;roth&#39;</span><span class="p">:</span>
            <span class="n">phi</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="n">X</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">conj</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">)</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">filt</span> <span class="o">==</span> <span class="s1">&#39;scot&#39;</span><span class="p">:</span>
            <span class="n">Gxx</span> <span class="o">=</span> <span class="n">X</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">conj</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="n">Gyy</span> <span class="o">=</span> <span class="n">Y</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">conj</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
            <span class="n">phi</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">X</span> <span class="o">*</span> <span class="n">Y</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">epsilon</span><span class="p">)</span>


        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">filt</span> <span class="o">==</span> <span class="s1">&#39;cc&#39;</span><span class="p">:</span>
            <span class="n">phi</span> <span class="o">=</span> <span class="mf">1.0</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Unsupported filter function&#39;</span><span class="p">)</span>


        <span class="n">cc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">irfft</span><span class="p">(</span><span class="n">Gxy</span> <span class="o">*</span> <span class="n">phi</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>

        <span class="n">max_shift</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">cc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">cc</span><span class="p">[:,</span> <span class="o">-</span><span class="n">max_shift</span><span class="p">:],</span> <span class="n">cc</span><span class="p">[:,</span> <span class="p">:</span><span class="n">max_shift</span><span class="o">+</span><span class="mi">1</span><span class="p">]),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">cc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                <span class="p">(</span><span class="n">cc</span><span class="p">[:,</span> <span class="p">:,</span> <span class="o">-</span><span class="n">max_shift</span><span class="p">:],</span> <span class="n">cc</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:</span><span class="n">max_shift</span><span class="o">+</span><span class="mi">1</span><span class="p">]),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">cc</span> </div></div>

<div class="viewcode-block" id="ipd"><a class="viewcode-back" href="../../../../acoustic/generated/preprocessing/transform/pysensing.acoustic.preprocessing.transform.ipd.html#pysensing.acoustic.preprocessing.transform.ipd">[docs]</a><span class="k">class</span> <span class="nc">ipd</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute Interaural Phase Difference (IPD), cosine of IPD (cosIPD), or sine of IPD (sinIPD) spatial features.</span>

<span class="sd">    The IPD of two signals is defined as:</span>

<span class="sd">    .. math::</span>
<span class="sd">        \text{IPD}(\omega) = \angle \left( \frac{X_1(\omega)}{X_2(\omega)} \right)</span>

<span class="sd">    The cosIPD and sinIPD are computed as:</span>

<span class="sd">    .. math::</span>
<span class="sd">        \cos(\text{IPD}(\omega)) = \cos \left( \angle \left( \frac{X_1(\omega)}{X_2(\omega)} \right) \right)</span>

<span class="sd">    .. math::</span>
<span class="sd">        \sin(\text{IPD}(\omega)) = \sin \left( \angle \left( \frac{X_1(\omega)}{X_2(\omega)} \right) \right)</span>

<span class="sd">    Args:</span>
<span class="sd">        cos (bool): Whether to return cosine of phase difference. Default is False.</span>
<span class="sd">        sin (bool): Whether to return sine of phase difference. Default is False.</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; import pysensing.acoustic.preprocessing.transform as T</span>
<span class="sd">        &gt;&gt;&gt; ipd_trans = T.ipd()</span>
<span class="sd">        &gt;&gt;&gt; ipd = ipd_trans(waveform1, waveform2)</span>

<span class="sd">    Reference:</span>
<span class="sd">        https://github.com/axeber01/ngcc/blob/main/model.py</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">cos</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">sin</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cos</span> <span class="o">=</span> <span class="n">cos</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sin</span> <span class="o">=</span> <span class="n">sin</span>

<div class="viewcode-block" id="ipd.forward"><a class="viewcode-back" href="../../../../acoustic/generated/preprocessing/transform/pysensing.acoustic.preprocessing.transform.ipd.html#pysensing.acoustic.preprocessing.transform.ipd.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">wave1_stft</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span><span class="n">wave2_stft</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            si_stft (torch.Tensor): Short-Time Fourier Transform of the first audio signal</span>
<span class="sd">            sj_stft (torch.Tensor): Short-Time Fourier Transform of the second audio signal</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: IPD if cos and sin are both False</span>
<span class="sd">                        cosine of phase difference if cos is True</span>
<span class="sd">                        sine of phase difference if sin is True</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ipd_mat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">angle</span><span class="p">(</span><span class="n">wave1_stft</span><span class="p">)</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">angle</span><span class="p">(</span><span class="n">wave2_stft</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">cos</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">sin</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">ipd_mat</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cos</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">sin</span><span class="p">:</span>
            <span class="n">cos_ipd</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">ipd_mat</span><span class="p">)</span>
            <span class="n">sin_ipd</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">ipd_mat</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">cos_ipd</span><span class="p">,</span> <span class="n">sin_ipd</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cos</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">ipd_mat</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">sin</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">ipd_mat</span><span class="p">)</span></div></div>
        
<div class="viewcode-block" id="amplitude2db"><a class="viewcode-back" href="../../../../acoustic/generated/preprocessing/transform/pysensing.acoustic.preprocessing.transform.amplitude2db.html#pysensing.acoustic.preprocessing.transform.amplitude2db">[docs]</a><span class="k">class</span> <span class="nc">amplitude2db</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Transform the spectrogram into dB scale.</span>

<span class="sd">    The transformation of a spectrogram to dB scale is defined as:</span>

<span class="sd">    .. math::</span>
<span class="sd">        \text{dB} = 10 \cdot \log_{10}(\text{S}) \quad \text{if stype} = \text{&quot;power&quot;}</span>

<span class="sd">    .. math::</span>
<span class="sd">        \text{dB} = 20 \cdot \log_{10}(\text{S}) \quad \text{if stype} = \text{&quot;magnitude&quot;}</span>

<span class="sd">    where:</span>
<span class="sd">    - :math:`\text{S}` is the input spectrogram.</span>

<span class="sd">    Args:</span>
<span class="sd">        stype (str, optional): scale of input tensor (``&quot;power&quot;`` or ``&quot;magnitude&quot;``). The</span>
<span class="sd">            power being the elementwise square of the magnitude. (Default: ``&quot;power&quot;``)</span>
<span class="sd">        top_db (float or None, optional): minimum negative cut-off in decibels.  A reasonable</span>
<span class="sd">            number is 80. (Default: ``None``)</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; import pysensing.acoustic.preprocessing.transform as T</span>
<span class="sd">        &gt;&gt;&gt; aplitude2db_trans    = T.aplitude2db(n_fft=400)</span>
<span class="sd">        &gt;&gt;&gt; spectrogram_db       = aplitude2db_trans(waveform)</span>

<span class="sd">    Note:</span>
<span class="sd">        The implementation is based on torchaudio.transforms.AmplitudeToDB.</span>

<span class="sd">    Reference: </span>
<span class="sd">        https://pytorch.org/audio/main/generated/torchaudio.transforms.AmplitudeToDB.html?highlight=todb#torchaudio.transforms.AmplitudeToDB</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">stype</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;power&#39;</span><span class="p">,</span> 
        <span class="n">top_db</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">amplitude2db</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transformation</span> <span class="o">=</span> <span class="n">torchaudio</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">AmplitudeToDB</span><span class="p">(</span>
            <span class="n">stype</span> <span class="o">=</span> <span class="n">stype</span><span class="p">,</span>
            <span class="n">top_db</span> <span class="o">=</span> <span class="n">top_db</span>
        <span class="p">)</span>

<div class="viewcode-block" id="amplitude2db.forward"><a class="viewcode-back" href="../../../../acoustic/generated/preprocessing/transform/pysensing.acoustic.preprocessing.transform.amplitude2db.html#pysensing.acoustic.preprocessing.transform.amplitude2db.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">waveform</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            waveform (Tensor): Tensor of audio </span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor: spectrogram in db scale</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">spectrogram_db_result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformation</span><span class="p">(</span><span class="n">waveform</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">spectrogram_db_result</span></div></div>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2024, Pysensing Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>
<!--        <div class="pytorch-content-right" id="pytorch-content-right">-->
<!--          <div class="pytorch-right-menu" id="pytorch-right-menu">-->
<!--              <a class="twitter-timeline" data-width="100%" href="https://twitter.com/pypose_org?ref_src=twsrc%5Etfw">News from Twitter @pypose_rog<br>You need VPN if you see this.</a> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>-->
<!--          </div>-->
<!--        </div>-->
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
         <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
         <script src="../../../../_static/jquery.js"></script>
         <script src="../../../../_static/underscore.js"></script>
         <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../../../../_static/doctools.js"></script>
         <script src="../../../../_static/katex.min.js"></script>
         <script src="../../../../_static/auto-render.min.js"></script>
         <script src="../../../../_static/katex_autorenderer.js"></script>
     

  

  <script type="text/javascript" src="../../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access documentation for Pysensing</p>
          <a class="with-right-arrow" href="https://www.pysensing.org/docs">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get started with tutorials and examples</p>
          <a class="with-right-arrow" href="https://www.pysensing.org/tutorial/">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Get Started</h2>
          <p>Find resources and how to start using pysensing</p>
          <a class="with-right-arrow" href="https://pysensing.org/get-started/locally">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://www.pysensing.org" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://www.pysensing.org">Pysensing</a></li>
            <li><a href="https://www.pysensing.org/get-started/locally">Get Started</a></li>
            <!-- <li><a href="https://github.com/pysensing/pysensing">Features</a></li> -->
            <li><a href="https://github.com/pysensing/pysensing">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://github.com/pysensing/pysensing">Resources</a></li>
            <li><a href="https://www.pysensing.org/tutorial/">Tutorials</a></li>
            <li><a href="https://www.pysensing.org/docs">Docs</a></li>
            <!-- <li><a href="https://github.com/pysensing/pysensing/issues" target="_blank">Github Issues</a></li> -->
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <!-- <li><a href="https://github.com/pysensing/pysensing" target="_blank">Twitter</a></li> -->
            <li><a href="https://github.com/pysensing/pysensing" target="_blank">GitHub</a></li>

          </ul>  
          </div>
        </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebooks Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://www.pysensing.org" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://www.pysensing.org/get-started/locally">Get Started</a>
          </li>
          <li>
            <a href="https://www.pysensing.org/tutorial/">Tutorials</a>
          </li>
          <li>
            <a href="https://www.pysensing.org/docs">Docs</a>
          </li>
          <li>
            <a href="https://www.pysensing.org/about-us">About Us</a>
          </li>
          <li>
            <a href="https://github.com/pysensing/pysensing">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>